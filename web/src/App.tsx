import { useEffect, useRef, useState } from 'react'
import { Mic, Square, Brain, Folder, CheckCircle2, AlertCircle, Loader2 } from 'lucide-react'
import './App.css'

type FormatId = 'official' | 'minutes' | 'summary' | 'blog'

const formatOptions: { id: FormatId; label: string }[] = [
  { id: 'official', label: 'ê³µë¬¸ ì‘ì„±' },
  { id: 'minutes', label: 'íšŒì˜ë¡' },
  { id: 'summary', label: 'ìš”ì•½ë¬¸' },
  { id: 'blog', label: 'ë¸”ë¡œê·¸ ê¸€' },
]

type SavedDoc = { id: string; title: string; content: string; createdAt: number; formatId: FormatId }

function App() {
  const [isRecording, setIsRecording] = useState(false)
  const isRecordingRef = useRef(false)
  const [transcript, setTranscript] = useState('')
  const [formatId, setFormatId] = useState<FormatId>('summary')
  const [composedText, setComposedText] = useState('')
  const [savedDocs, setSavedDocs] = useState<SavedDoc[]>([])
  const [geminiEnabled, setGeminiEnabled] = useState<boolean | null>(null)
  const [instruction, setInstruction] = useState('')
  const [activeTab, setActiveTab] = useState<'record' | 'compose' | 'saved'>('record')
  const [isComposing, setIsComposing] = useState(false)
  const recognitionRef = useRef<any>(null)
  const recordRef = useRef<HTMLDivElement | null>(null)
  const composeRef = useRef<HTMLDivElement | null>(null)
  const savedRef = useRef<HTMLDivElement | null>(null)
  const wakeLockRef = useRef<any>(null)
  // ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ë£¨í”„ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì¬ì‹œë„ ì •ë³´
  const restartInfoRef = useRef<{ count: number; last: number }>({ count: 0, last: 0 })
  // ì¤‘ë³µ ì¬ì‹œì‘ ì˜ˆì•½ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ íƒ€ì´ë¨¸ í•¸ë“¤
  const restartTimeoutRef = useRef<number | null>(null)
  // ë§ì´ ë©ˆì¶˜ ì´í›„ ìë™ ì¢…ë£Œ ì„ê³„ì‹œê°„(ë¬´ìŒ ì§€ì† ì‹œê°„)
  const SILENCE_RESTART_DELAY_MS = 20000 // 20ì´ˆ (ê¸´ ë¬´ìŒ í›„ ìë™ ì¢…ë£Œ)
  const silenceTimeoutRef = useRef<number | null>(null)
  const silenceWatcherRef = useRef<number | null>(null)
  const lastSpeechTsRef = useRef<number>(Date.now())
  // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ ìœ ì§€í•˜ê³  ì—ë„ˆì§€ë¥¼ ê°ì§€í•˜ì—¬ ë¬´ìŒ íŒë‹¨ì„ ë³´ì™„
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const audioCtxRef = useRef<AudioContext | null>(null)
  const sourceNodeRef = useRef<MediaStreamAudioSourceNode | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const gainNodeRef = useRef<GainNode | null>(null)
  const energyWatcherRef = useRef<number | null>(null)
  const recWatchRef = useRef<number | null>(null)
  const ENERGY_CHECK_INTERVAL_MS = 400
  const ENERGY_RMS_THRESHOLD = 0.008 // ë§ì†Œë¦¬ ì¡´ì¬ ì¶”ì • ì„ê³„ê°’(ëª¨ë°”ì¼ ë§ˆì´í¬ ê°ë„ ê³ ë ¤í•˜ì—¬ ë‚®ì¶¤)
  const API_BASE = (import.meta.env.VITE_API_BASE as string) || window.location.origin

  // í•˜ì´ë¸Œë¦¬ë“œ ë…¹ìŒ: AndroidëŠ” MediaRecorder, iOSëŠ” Web Speech API
  const [useMediaRecorder, setUseMediaRecorder] = useState(false)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const CHUNK_INTERVAL_MS = 8000 // 8ì´ˆë§ˆë‹¤ ì²­í¬ ì „ì†¡ (STT ì¸ì‹ë¥  í–¥ìƒ)
  const [debugInfo, setDebugInfo] = useState<string>('')

  useEffect(() => {
    // ë¡œì»¬ ì €ì¥ëœ ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
    const raw = localStorage.getItem('audioToTextDocs')
    if (raw) {
      try {
        setSavedDocs(JSON.parse(raw))
      } catch {}
    }
  }, [])

  useEffect(() => {
    localStorage.setItem('audioToTextDocs', JSON.stringify(savedDocs))
  }, [savedDocs])

  useEffect(() => {
    // ì„œë²„ í—¬ìŠ¤ ì²´í¬ë¡œ Twilio ì„¤ì • ì—¬ë¶€ í™•ì¸
    const checkHealth = async () => {
      try {
        const resp = await fetch(`${API_BASE}/api/health`)
        const data = await resp.json()
        setGeminiEnabled(!!data?.geminiConfigured)
      } catch {
        setGeminiEnabled(null)
      }
    }
    checkHealth()
  }, [])

  // ë¼ì´íŠ¸ ëª¨ë“œ ì œê±°: ê¸°ë³¸ ë‹¤í¬ ëª¨ë“œ ê³ ì •
  useEffect(() => {
    document.documentElement.dataset.theme = ''
  }, [])

  // í”Œë«í¼ ê°ì§€: AndroidëŠ” MediaRecorder, iOSëŠ” Web Speech API
  useEffect(() => {
    const isAndroid = /Android/.test(navigator.userAgent)

    // Android Chromeì—ì„œë§Œ MediaRecorder ì‚¬ìš© (ëŠê¹€ ì—†ìŒ)
    // iOS SafariëŠ” Web Speech API ìœ ì§€ (ëŠê¹€ ìˆì§€ë§Œ ì‘ë™)
    if (isAndroid && typeof MediaRecorder !== 'undefined') {
      setUseMediaRecorder(true)
      console.log('Android ê°ì§€: MediaRecorder ëª¨ë“œ í™œì„±í™”')
    } else {
      setUseMediaRecorder(false)
      console.log('iOS ë˜ëŠ” ê¸°íƒ€ í”Œë«í¼: Web Speech API ëª¨ë“œ')
    }
  }, [])

  const scrollTo = (ref: React.RefObject<HTMLDivElement | null>, tab: 'record' | 'compose' | 'saved') => {
    try {
      ref.current?.scrollIntoView({ behavior: 'smooth', block: 'start' })
      setActiveTab(tab)
    } catch {}
  }

  // AudioContext/MediaStream ì‹œì‘: ë§ˆì´í¬ ê²½ë¡œë¥¼ ìœ ì§€í•˜ê³  ì—ë„ˆì§€(RMS)ë¡œ ë°œí™” ê°ì§€
  const startMicStream = async () => {
    try {
      if (!navigator.mediaDevices?.getUserMedia) return
      if (mediaStreamRef.current) {
        try { await audioCtxRef.current?.resume?.() } catch {}
        return
      }
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: { noiseSuppression: false, echoCancellation: false, autoGainControl: false },
      })
      mediaStreamRef.current = stream
      const AC: any = (window as any).AudioContext || (window as any).webkitAudioContext
      if (!AC) return
      const ctx: AudioContext = new AC()
      audioCtxRef.current = ctx
      const src = ctx.createMediaStreamSource(stream)
      sourceNodeRef.current = src
      const analyser = ctx.createAnalyser()
      analyser.fftSize = 2048
      analyserRef.current = analyser
      src.connect(analyser)
      // ë¬´ì¶œë ¥(ë¬´ìŒ) ë¼ìš°íŒ…ìœ¼ë¡œ ì˜¤ë””ì˜¤ ê²½ë¡œ ìœ ì§€ (ì¼ë¶€ iOS ì¥ì¹˜ì—ì„œ í•„ìš”)
      const gain = ctx.createGain()
      gain.gain.value = 0
      gainNodeRef.current = gain
      src.connect(gain)
      gain.connect(ctx.destination)

      if (energyWatcherRef.current) {
        clearInterval(energyWatcherRef.current)
        energyWatcherRef.current = null
      }
      energyWatcherRef.current = window.setInterval(() => {
        try {
          const a = analyserRef.current
          if (!a) return
          const buf = new Float32Array(a.fftSize)
          a.getFloatTimeDomainData(buf)
          let sum = 0
          for (let i = 0; i < buf.length; i++) sum += buf[i] * buf[i]
          const rms = Math.sqrt(sum / buf.length)
          if (rms > ENERGY_RMS_THRESHOLD) {
            lastSpeechTsRef.current = Date.now()
          }
        } catch {}
      }, ENERGY_CHECK_INTERVAL_MS)
    } catch (e) {
      console.warn('startMicStream failed:', e)
    }
  }

  const stopMicStream = () => {
    try {
      if (energyWatcherRef.current) {
        clearInterval(energyWatcherRef.current)
        energyWatcherRef.current = null
      }
      try { gainNodeRef.current?.disconnect?.() } catch {}
      try { sourceNodeRef.current?.disconnect?.() } catch {}
      try { audioCtxRef.current?.close?.() } catch {}
      audioCtxRef.current = null
      analyserRef.current = null
      gainNodeRef.current = null
      sourceNodeRef.current = null
      if (mediaStreamRef.current) {
        try { mediaStreamRef.current.getTracks().forEach(t => t.stop()) } catch {}
        mediaStreamRef.current = null
      }
    } catch (e) {
      console.warn('stopMicStream failed:', e)
    }
  }

  const startRecWatchdog = () => {
    if (recWatchRef.current) {
      clearInterval(recWatchRef.current)
      recWatchRef.current = null
    }
    recWatchRef.current = window.setInterval(() => {
      try {
        if (!isRecordingRef.current) return
        const rec = recognitionRef.current
        // ì¸ì‹ ê°ì²´ê°€ ì‚¬ë¼ì¡Œê³ , ë¬´ìŒ íƒ€ì„ì•„ì›ƒì— ë„ë‹¬í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ë³µêµ¬ ì‹œë„
        const silenceFor = Date.now() - lastSpeechTsRef.current
        if (!rec && silenceFor < SILENCE_RESTART_DELAY_MS) {
          console.warn('Recognition missing; respawning...')
          // ê°„ë‹¨ ë³µêµ¬: í”Œë˜ê·¸ë¥¼ ë‚´ë ¸ë‹¤ê°€ ì¬ì‹œì‘ í˜¸ì¶œ
          isRecordingRef.current = false
          setIsRecording(false)
          startRecording()
        }
      } catch {}
    }, 7000)
  }

  const stopRecWatchdog = () => {
    if (recWatchRef.current) {
      clearInterval(recWatchRef.current)
      recWatchRef.current = null
    }
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë…¹ìŒ ê°•ì œ ì¢…ë£Œ(ì”ì—¬ ì´ë²¤íŠ¸ë¡œ ì¬ì‹œì‘ë˜ëŠ” ë¬¸ì œ ì˜ˆë°©)
  useEffect(() => {
    return () => {
      try {
        const rec = recognitionRef.current
        if (rec) rec.stop()
        recognitionRef.current = null
        try { awaitWakeRelease() } catch {}
        try { stopMicStream() } catch {}
        try { stopRecWatchdog() } catch {}
      } catch {}
    }
  }, [])

  const acquireWakeLock = async () => {
    try {
      const navAny = navigator as any
      if (navAny?.wakeLock && !wakeLockRef.current) {
        const sentinel = await navAny.wakeLock.request('screen')
        wakeLockRef.current = sentinel
        sentinel.addEventListener?.('release', () => { wakeLockRef.current = null })
      }
    } catch (e) {
      console.warn('wakeLock request failed:', e)
    }
  }

  const awaitWakeRelease = async () => {
    try { await wakeLockRef.current?.release?.() } catch {}
    wakeLockRef.current = null
  }

  // ì¬ì‹œì‘ ì¹´ìš´í„° ì´ˆê¸°í™”
  const resetRestartInfo = () => {
    restartInfoRef.current.count = 0
    restartInfoRef.current.last = Date.now()
    // ì¬ì‹œì‘ ì˜ˆì•½ì´ ë‚¨ì•„ìˆìœ¼ë©´ ì¦‰ì‹œ í•´ì œ
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current)
      restartTimeoutRef.current = null
    }
    // ì¹¨ë¬µ íƒ€ì´ë¨¸ë„ í´ë¦¬ì–´
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current)
      silenceTimeoutRef.current = null
    }
  }

  const clearSilenceTimeout = () => {
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current)
      silenceTimeoutRef.current = null
    }
  }

  const startSilenceWatcher = () => {
    // ì£¼ê¸°ì ìœ¼ë¡œ ë§ˆì§€ë§‰ ë°œí™” ì‹œì ê³¼ í˜„ì¬ ì‹œê°„ì„ ë¹„êµí•˜ì—¬ ë¬´ìŒ 20ì´ˆ ì´ˆê³¼ ì‹œ ìë™ ì¢…ë£Œ
    if (silenceWatcherRef.current) {
      clearInterval(silenceWatcherRef.current)
      silenceWatcherRef.current = null
    }
    silenceWatcherRef.current = window.setInterval(() => {
      if (!isRecordingRef.current) {
        clearInterval(silenceWatcherRef.current!)
        silenceWatcherRef.current = null
        return
      }
      const silenceFor = Date.now() - lastSpeechTsRef.current
      // 20ì´ˆ ë¬´ìŒ ì‹œ ìë™ ì¢…ë£Œ (ëª¨ë°”ì¼ì—ì„œ ê¸´ ëŒ€ê¸° ì‹œê°„ í™•ë³´)
      if (silenceFor >= 20000) {
        console.log('20ì´ˆ ë¬´ìŒ ê°ì§€, ë…¹ìŒ ì¢…ë£Œ')
        stopRecording()
      }
    }, 1000)
  }

  useEffect(() => {
    const onVis = () => {
      if (document.visibilityState === 'visible' && isRecordingRef.current) {
        acquireWakeLock()
        try { audioCtxRef.current?.resume?.() } catch {}
      }
    }
    document.addEventListener('visibilitychange', onVis)
    return () => document.removeEventListener('visibilitychange', onVis)
  }, [])

  // MediaRecorder ë°©ì‹: ëŠê¹€ ì—†ëŠ” ë…¹ìŒ (Android)
  const startMediaRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      mediaStreamRef.current = stream

      // MIME íƒ€ì… ê°ì§€ (Android: webm, iOS: mp4)
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : 'audio/mp4'

      const recorder = new MediaRecorder(stream, { mimeType })
      mediaRecorderRef.current = recorder

      recorder.ondataavailable = async (event) => {
        if (event.data.size > 0) {
          const timestamp = new Date().toLocaleTimeString()
          setDebugInfo(`[${timestamp}] ì²­í¬: ${event.data.size} bytes`)
          console.log(`[MediaRecorder] ì²­í¬ ìƒì„±: ${event.data.size} bytes`)

          // ì¦‰ì‹œ ì„œë²„ë¡œ ì „ì†¡í•˜ì—¬ STT ì²˜ë¦¬
          try {
            const reader = new FileReader()
            reader.onloadend = async () => {
              const base64 = (reader.result as string).split(',')[1]
              setDebugInfo(prev => `${prev}\n[${timestamp}] STT ì „ì†¡ ì¤‘...`)
              console.log(`[STT] ì „ì†¡ ì‹œì‘: ${base64?.length || 0} chars`)

              try {
                const resp = await fetch(`${API_BASE}/api/stt/recognize-chunk`, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({ audioData: base64, mimeType }),
                })
                const data = await resp.json()

                console.log('[STT] ì‘ë‹µ:', data)

                if (data.text) {
                  setDebugInfo(prev => `${prev}\n[${timestamp}] âœ… "${data.text}"`)
                  // í•¨ìˆ˜í˜• ì—…ë°ì´íŠ¸ë¡œ ìµœì‹  ìƒíƒœ ì°¸ì¡°
                  setTranscript(prev => {
                    const updated = prev ? prev + '\n' + data.text : data.text
                    console.log(`[í…ìŠ¤íŠ¸] ì—…ë°ì´íŠ¸ ì™„ë£Œ (ì´ ${updated.length} chars)`)
                    return updated
                  })
                } else {
                  setDebugInfo(prev => `${prev}\n[${timestamp}] âš ï¸ ë¬´ìŒ/ì¸ì‹ì‹¤íŒ¨`)
                  console.warn('[STT] ê²°ê³¼ ì—†ìŒ (ë¬´ìŒ ë˜ëŠ” ì¸ì‹ ì‹¤íŒ¨)')
                }
              } catch (err) {
                setDebugInfo(prev => `${prev}\n[${timestamp}] âŒ ì˜¤ë¥˜: ${err}`)
                console.error('[STT] ì „ì†¡ ì‹¤íŒ¨:', err)
              }
            }
            reader.readAsDataURL(event.data)
          } catch (err) {
            console.error('[FileReader] ì‹¤íŒ¨:', err)
          }
        } else {
          console.warn('[MediaRecorder] ë¹ˆ ì²­í¬ ìˆ˜ì‹ ')
        }
      }

      recorder.onerror = (event) => {
        console.error('[MediaRecorder] ì˜¤ë¥˜:', event)
      }

      recorder.onstop = () => {
        console.log('[MediaRecorder] ì •ì§€ë¨')
      }

      // 5ì´ˆë§ˆë‹¤ ìë™ìœ¼ë¡œ ondataavailable í˜¸ì¶œ (timeslice)
      recorder.start(CHUNK_INTERVAL_MS)
      console.log(`[MediaRecorder] ì‹œì‘: ${mimeType}, ${CHUNK_INTERVAL_MS}ms ì²­í¬`)

      setIsRecording(true)
      isRecordingRef.current = true
      acquireWakeLock()
    } catch (err) {
      console.error('[MediaRecorder] ì‹œì‘ ì‹¤íŒ¨:', err)
      alert('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ ì£¼ì„¸ìš”.')
    }
  }

  const stopMediaRecording = () => {
    console.log('[MediaRecorder] ì •ì§€ ìš”ì²­')

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      try {
        mediaRecorderRef.current.stop()
      } catch (err) {
        console.error('[MediaRecorder] ì •ì§€ ì‹¤íŒ¨:', err)
      }
      mediaRecorderRef.current = null
    }

    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop())
      mediaStreamRef.current = null
    }

    setIsRecording(false)
    isRecordingRef.current = false
    awaitWakeRelease()
  }

  const startRecording = async () => {
    // Android: MediaRecorder ì‚¬ìš© (ëŠê¹€ ì—†ìŒ)
    if (useMediaRecorder) {
      return startMediaRecording()
    }

    // iOS: Web Speech API ì‚¬ìš© (ëŠê¹€ ìˆì§€ë§Œ ì‘ë™)
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    if (!SpeechRecognition) {
      alert('ë¸Œë¼ìš°ì €ê°€ ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chromeì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.')
      return
    }
    if (isRecording || recognitionRef.current) return

    const recognition = new SpeechRecognition()
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = 'ko-KR'
    // ì¼ë¶€ ê¸°ê¸°ì—ì„œ ëŒ€ì•ˆ ê²°ê³¼ê°€ ë§ìœ¼ë©´ ì§€ì—°ì´ ëŠ˜ì–´ë‚˜ëŠ” ë¬¸ì œê°€ ìˆì–´ 1ë¡œ ì œí•œ
    try { (recognition as any).maxAlternatives = 1 } catch {}
    isRecordingRef.current = true

    // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ë° ì—ë„ˆì§€ ê°ì‹œ ì‹œì‘(ì¸ì‹ ì—”ì§„ê³¼ ë³„ê°œë¡œ ì˜¤ë””ì˜¤ ê²½ë¡œ ìœ ì§€)
    try { await startMicStream() } catch {}

    const attachHandlers = (rec: any) => {
      let finalText = transcript
      rec.onresult = (event: any) => {
        // ëª¨ë“  onresult í˜¸ì¶œ ì‹œ íƒ€ì„ìŠ¤íƒ¬í”„ ê°±ì‹ í•˜ì—¬ ì—°ì†ì„± ìœ ì§€
        lastSpeechTsRef.current = Date.now()
        let interim = ''
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i]
          const text = result[0].transcript
          if (result.isFinal) {
            finalText += (finalText ? '\n' : '') + text.trim()
            setTranscript(finalText)
          } else {
            interim += text
          }
        }
      }
      rec.onerror = (e: any) => {
        console.error('Recognition error:', e)
        const restartable = ['no-speech', 'network', 'aborted', 'audio-capture']
        if (isRecordingRef.current && restartable.includes(e?.error)) {
          attemptRestart('error')
        }
        if (e?.error === 'not-allowed') {
          alert('ë§ˆì´í¬ ê¶Œí•œì´ í—ˆìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì €/OS ê¶Œí•œì„ í™•ì¸í•´ ì£¼ì„¸ìš”.')
          stopRecording()
        }
      }
      ;(rec as any).onspeechstart = () => { lastSpeechTsRef.current = Date.now(); clearSilenceTimeout() }
      // onspeechend ì¬ì‹œì‘ ë¡œì§ ì œê±°: ëª¨ë°”ì¼ì—ì„œ ì§§ì€ ë¬´ìŒì—ë„ ë¹ˆë²ˆíˆ ë°œìƒí•˜ì—¬ ëŠê¹€ í˜„ìƒ ìœ ë°œ
      ;(rec as any).onspeechend = () => { /* ì¬ì‹œì‘ ë¡œì§ ì œê±° - ì—ë„ˆì§€ ê°ì§€ì™€ silenceWatcherë§Œ í™œìš© */ }
      rec.onend = () => {
        if (!isRecordingRef.current) {
          setIsRecording(false)
          recognitionRef.current = null
          return
        }
        // ê°¤ëŸ­ì‹œ ë“± ëª¨ë°”ì¼ì—ì„œ onendê°€ ë¹ˆë²ˆíˆ ë°œìƒí•˜ì—¬ ëŠê¹€ ìœ ë°œ
        // ë§ˆì§€ë§‰ ë°œí™” ì´í›„ 20ì´ˆ ì´ìƒ ê²½ê³¼í–ˆì„ ë•Œë§Œ ì¬ì‹œì‘ ì‹œë„
        const silenceFor = Date.now() - lastSpeechTsRef.current
        if (silenceFor < 20000) {
          // 20ì´ˆ ë¯¸ë§Œì´ë©´ ì¦‰ì‹œ ì¬ì‹œì‘í•˜ì—¬ ëŠê¹€ ì—†ì´ ìœ ì§€
          setIsRecording(true)
          attemptRestart('silence')
        } else {
          // 20ì´ˆ ì´ìƒ ë¬´ìŒì´ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì¢…ë£Œ ëŒ€ê¸°
          setIsRecording(true)
        }
      }
      ;(rec as any).onstart = () => {
        try { acquireWakeLock() } catch {}
        resetRestartInfo()
        try {
          ;(rec as any).continuous = true
          ;(rec as any).interimResults = true
        } catch {}
      }
    }

    const attemptRestart = (cause: 'error' | 'silence' = 'error') => {
      if (!isRecordingRef.current) return
      const now = Date.now()
      const isBurst = now - restartInfoRef.current.last < 300
      restartInfoRef.current.last = now
      // ì˜¤ë¥˜ì— ì˜í•œ ì¬ì‹œì‘ë§Œ ë£¨í”„ ì¹´ìš´íŠ¸ì— í¬í•¨í•˜ê³ , ì¹¨ë¬µì— ì˜í•œ ì¬ì‹œì‘ì€ ì¹´ìš´íŠ¸ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤.
      if (cause === 'error') {
        restartInfoRef.current.count = isBurst ? restartInfoRef.current.count + 1 : 0
      } else {
        restartInfoRef.current.count = 0
      }

      // ì˜¤ë¥˜ë¡œ ì¸í•œ ì¬ì‹œì‘ì´ ê³¼ë„í•˜ê²Œ ë°˜ë³µë˜ë©´ ì¬ì‹œë„ë§Œ ì¤‘ë‹¨í•˜ê³ , 20ì´ˆ ìë™ ì¢…ë£Œë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
      if (cause === 'error' && restartInfoRef.current.count >= 5) {
        console.warn('ìŒì„± ì¸ì‹ ì˜¤ë¥˜ê°€ ë°˜ë³µë˜ì–´ ì¬ì‹œì‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤. 20ì´ˆ í›„ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.')
        alert('ë§ˆì´í¬ ì…ë ¥ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤. ì¬ì‹œë„ëŠ” ì¤‘ë‹¨í•˜ê³  20ì´ˆ ë¬´ìŒ í›„ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.')
        return
      }

      const rec = recognitionRef.current
      if (cause === 'silence') {
        // ì¦‰ì‹œ ì¬ì‹œì‘ìœ¼ë¡œ ëŠê¹€ ì™„ì „ ì œê±°
        if (restartTimeoutRef.current) return
        restartTimeoutRef.current = window.setTimeout(() => {
          restartTimeoutRef.current = null
          if (!isRecordingRef.current) return
          try {
            try { rec?.stop?.() } catch {}
            rec?.start()
          } catch (e) {
            console.warn('Silence restart failed:', e)
            // ì‹¤íŒ¨ ì‹œ ìƒˆ ì¸ì‹ ê°ì²´ ìƒì„±
            const SR: any = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
            if (SR) {
              const newRec = new SR()
              newRec.continuous = true
              newRec.interimResults = true
              newRec.lang = 'ko-KR'
              try { (newRec as any).maxAlternatives = 1 } catch {}
              recognitionRef.current = newRec
              attachHandlers(newRec)
              try { newRec.start() } catch {}
            }
          }
        }, 100)  // 100msë¡œ ìµœì†Œí™”í•˜ì—¬ ëŠê¹€ ì—†ì´ ì¦‰ì‹œ ì¬ì‹œì‘
        return
      }

      // ì˜¤ë¥˜ë¡œ ì¸í•œ ì¬ì‹œì‘ì€ ì ì§„ì  ë°±ì˜¤í”„(ìµœëŒ€ 3ì´ˆ)
      if (restartTimeoutRef.current) return
      const delay = Math.min(200 + restartInfoRef.current.count * 400, 3000)
      restartTimeoutRef.current = window.setTimeout(() => {
        restartTimeoutRef.current = null
        if (!isRecordingRef.current) return
        try {
          try { rec?.stop?.() } catch {}
          rec?.start()
        } catch {
          // ì¬ì‹œì‘ ì‹¤íŒ¨ ì‹œ ì†Œí­ ì§€ì—° í›„ 1íšŒ ì¶”ê°€ ì‹œë„
          const retryDelay = 400
          restartTimeoutRef.current = window.setTimeout(() => {
            restartTimeoutRef.current = null
            if (isRecordingRef.current) {
              try {
                try { rec?.stop?.() } catch {}
                rec?.start()
              } catch {
                const SR: any = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
                if (SR) {
                  const newRec = new SR()
                  newRec.continuous = true
                  newRec.interimResults = true
                  newRec.lang = 'ko-KR'
                  try { (newRec as any).maxAlternatives = 1 } catch {}
                  recognitionRef.current = newRec
                  attachHandlers(newRec)
                  try { newRec.start() } catch {}
                }
              }
            }
          }, retryDelay)
        }
      }, delay)
    }

    attachHandlers(recognition)

    recognitionRef.current = recognition
    recognition.start()
    setIsRecording(true)
    lastSpeechTsRef.current = Date.now()
    startSilenceWatcher()
    acquireWakeLock()
    startRecWatchdog()
  }

  const stopRecording = () => {
    // Android: MediaRecorder ì •ì§€
    if (useMediaRecorder) {
      return stopMediaRecording()
    }

    // iOS: Web Speech API ì •ì§€
    const rec = recognitionRef.current
    // ì¬ì‹œì‘ ë£¨í”„ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë¨¼ì € í”Œë˜ê·¸ë¥¼ ë‚´ë¦¬ê³  ì´ë²¤íŠ¸ë¥¼ í•´ì œí•©ë‹ˆë‹¤.
    isRecordingRef.current = false
    setIsRecording(false)
    if (rec) {
      try {
        rec.onend = null
        rec.onerror = null
        ;(rec as any).onspeechend = null
        ;(rec as any).onsoundend = null
        ;(rec as any).onaudioend = null
      } catch {}
      try { (rec as any).abort?.() } catch {}
      try { rec.stop() } catch {}
      recognitionRef.current = null
    }
    awaitWakeRelease()
    // ì˜¤ë””ì˜¤ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    stopMicStream()
    stopRecWatchdog()
    // ì˜ˆì•½ëœ ì¬ì‹œì‘ ì‘ì—…ì´ ìˆìœ¼ë©´ ì·¨ì†Œ
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current)
      restartTimeoutRef.current = null
    }
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current)
      silenceTimeoutRef.current = null
    }
    if (silenceWatcherRef.current) {
      clearInterval(silenceWatcherRef.current)
      silenceWatcherRef.current = null
    }
  }

  const clearTranscript = () => {
    setTranscript('')
  }

  const composeWithGemini = async () => {
    if (geminiEnabled === false) {
      alert('ì„œë²„ì— Gemini ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤(.envì— GOOGLE_API_KEY ì„¤ì • í•„ìš”).')
      return
    }
    if (!transcript.trim()) {
      alert('ë¨¼ì € ìŒì„±ì„ ë…¹ìŒí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.')
      return
    }
    try {
      setIsComposing(true)
      const resp = await fetch(`${API_BASE}/api/compose`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ transcript, formatId, instruction: instruction.trim() }),
      })
      const data = await resp.json()
      if (!resp.ok) throw new Error(data?.error || 'Compose failed')
      setComposedText(data.text || '')
    } catch (err: any) {
      alert('ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: ' + (err?.message || String(err)))
    } finally {
      setIsComposing(false)
    }
  }

  const saveDocument = () => {
    const content = (composedText || transcript).trim()
    if (!content) {
      alert('ì €ì¥í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.')
      return
    }
    const title = formatOptions.find(f => f.id === formatId)?.label || 'ë¬¸ì„œ'
    const doc: SavedDoc = {
      id: Math.random().toString(36).slice(2),
      title,
      content,
      createdAt: Date.now(),
      formatId,
    }
    setSavedDocs(prev => [doc, ...prev])
  }

  const deleteDocument = (id: string) => {
    setSavedDocs(prev => prev.filter(d => d.id !== id))
  }

  const loadDocument = (id: string) => {
    const doc = savedDocs.find(d => d.id === id)
    if (doc) {
      setComposedText(doc.content)
      setFormatId(doc.formatId)
    }
  }

  const copyDocument = async (id: string) => {
    const doc = savedDocs.find(d => d.id === id)
    if (!doc) return
    try {
      await navigator.clipboard.writeText(doc.content)
      alert('ë¬¸ì„œ ë‚´ìš©ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.')
    } catch (e: any) {
      alert('ë³µì‚¬ ì‹¤íŒ¨: ' + (e?.message || String(e)))
    }
  }

  // (ë¬¸ì ë°œì†¡ ê¸°ëŠ¥ ì œê±°ë¨)

  return (
    <>
      <header className="topbar">
        <div className="topbar-inner container">
          <div className="brand" style={{ display: 'flex', alignItems: 'center', gap: 8 }}>
            <Mic size={18} />
            Audio â†’ Text Composer
          </div>
          <span className="subtitle">ìŠ¤ë§ˆíŠ¸í° ìµœì í™” Â· ì‹¤ì‹œê°„ ìŒì„± ì •ë¦¬</span>
          <span className="grow" />
          {geminiEnabled === true && (
            <span className="badge success" aria-label="Gemini ì¤€ë¹„ ì™„ë£Œ">
              <CheckCircle2 size={14} /> Gemini OK
            </span>
          )}
          {geminiEnabled === false && (
            <span className="badge danger" aria-label="Gemini ì„¤ì • í•„ìš”">
              <AlertCircle size={14} /> Gemini ì„¤ì • í•„ìš”
            </span>
          )}
        </div>
      </header>

      <main className="container main">
        <h1 className="app-title">ìŒì„±â†’í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ë¬¸ì„œí™”</h1>

        <section ref={recordRef} className="section" id="record">
          <h2 className="section-title" style={{ display: 'flex', alignItems: 'center', gap: 8 }}>
            <Mic size={18} /> 1) ìŒì„± ì¸ì‹ (ì •ì§€ê¹Œì§€ ì—°ì† ê¸°ë¡)
          </h2>
        <div className="controls">
          <button
            aria-label="ë…¹ìŒ í† ê¸€"
            title={isRecording ? 'ì •ì§€' : 'ë…¹ìŒ ì‹œì‘'}
            onClick={() => (isRecording ? stopRecording() : startRecording())}
            className={`icon-btn ${isRecording ? 'recording' : ''}`}
          >
            {isRecording ? <Square size={28} /> : <Mic size={28} />}
          </button>
          <button className="btn" onClick={clearTranscript}>ì´ˆê¸°í™”</button>
        </div>
        {isRecording && (navigator as any)?.wakeLock && (
          <p className="help"><AlertCircle size={14} /> ë…¹ìŒ ì¤‘ í™”ë©´ êº¼ì§ ë°©ì§€ í™œì„±(ì§€ì› ê¸°ê¸°). í™”ë©´ì„ ì¼  ìƒíƒœì—ì„œ ì‚¬ìš©í•˜ì„¸ìš”.</p>
        )}
          <p className="help">
            <Mic size={14} /> ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒì„ ì‹œì‘í•˜ê³ , ì •ì§€ ë²„íŠ¼ìœ¼ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤. ë…¹ìŒ ì¤‘ì—ëŠ” í…ìŠ¤íŠ¸ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ëˆ„ì ë©ë‹ˆë‹¤.
            {useMediaRecorder && (
              <><br/><CheckCircle2 size={14} /> Android ê°ì§€: ëŠê¹€ ì—†ëŠ” MediaRecorder ëª¨ë“œ í™œì„±í™”</>
            )}
            {!useMediaRecorder && (
              <><br/><AlertCircle size={14} /> iOS/ê¸°íƒ€: Web Speech API ëª¨ë“œ (ë§ì„ ë©ˆì¶”ë©´ ì¼ì‹œì ìœ¼ë¡œ ëŠê¸¸ ìˆ˜ ìˆìŒ)</>
            )}
          </p>
          <textarea
            value={transcript}
            onChange={(e) => setTranscript(e.target.value)}
            placeholder="ì—¬ê¸°ì— ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ëˆ„ì ë©ë‹ˆë‹¤."
            className="textarea-md mt-8"
          />
          {useMediaRecorder && debugInfo && (
            <div style={{ marginTop: 8, padding: 8, background: '#1a1a1a', border: '1px solid #333', borderRadius: 4, fontSize: 12, fontFamily: 'monospace', whiteSpace: 'pre-wrap', maxHeight: 200, overflow: 'auto' }}>
              <strong>ğŸ” ë””ë²„ê·¸ ë¡œê·¸:</strong>
              <br/>
              {debugInfo}
            </div>
          )}
        </section>

        <section ref={composeRef} className="section" id="compose">
          <h2 className="section-title" style={{ display: 'flex', alignItems: 'center', gap: 8 }}>
            <Brain size={18} /> 2) ë¬¸ì„œ í˜•ì‹ ì„ íƒ ë° ì‘ì„±
          </h2>
          <div className="controls">
            <label className="grow">
              í˜•ì‹
              <select value={formatId} onChange={(e) => setFormatId(e.target.value as FormatId)} className="mt-8">
                {formatOptions.map(f => (
                  <option key={f.id} value={f.id}>{f.label}</option>
                ))}
              </select>
            </label>
            <button className="btn btn-primary" onClick={composeWithGemini} disabled={geminiEnabled === false || isComposing} aria-busy={isComposing}>
              {isComposing ? (<><Loader2 size={16} /> ì‘ì„± ì¤‘...</>) : 'ì§€ì¹¨ëŒ€ë¡œ ë¬¸ì„œ ì‘ì„±'}
            </button>
          </div>
          <p className="help">
            {geminiEnabled === null && (<><AlertCircle size={14} /> ì„œë²„ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤.</>)}
            {geminiEnabled === false && (<><AlertCircle size={14} /> ì„œë²„ì— Gemini ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤(.envì— GOOGLE_API_KEY ì„¤ì •).</>)}
            {geminiEnabled === true && (<><CheckCircle2 size={14} /> Gemini ì„¤ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ ì‘ì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</>)}
          </p>
          <textarea
            value={instruction}
            onChange={(e) => setInstruction(e.target.value)}
            placeholder="ìˆ˜ì • ìš”ì²­/ì¶”ê°€ ì§€ì¹¨ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 300ì ì´ë‚´ ìš”ì•½, ê³µì†í•œ ì–´ì¡°ë¡œ ì¬ì‘ì„± ë“±)"
            className="textarea-sm mt-8"
          />
          <textarea
            value={composedText}
            onChange={(e) => setComposedText(e.target.value)}
            placeholder="ì„ íƒí•œ í˜•ì‹ê³¼ ìˆ¨ì€ í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ìƒì„±ëœ ë¬¸ì„œë¥¼ í¸ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            className="textarea-lg mt-8"
          />
          <div className="controls mt-8">
            <button className="btn" onClick={saveDocument}>ì €ì¥</button>
            <button className="btn btn-outline" onClick={() => setComposedText('')}>ì‚­ì œ(í¸ì§‘ì¤‘ì¸ ë¬¸ì„œ)</button>
          </div>
        </section>

        {/* STT/í¼ì§€ êµì • ì„¹ì…˜ ì œê±°ë¨ */}

        <section ref={savedRef} className="section" id="saved">
          <h2 className="section-title" style={{ display: 'flex', alignItems: 'center', gap: 8 }}>
            <Folder size={18} /> ì €ì¥ëœ ë¬¸ì„œ
          </h2>
          {savedDocs.length === 0 ? (
            <div className="empty-state">
              <Folder size={16} /> ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì‘ì„± í›„ ì €ì¥í•´ ë³´ì„¸ìš”.
            </div>
          ) : (
            <ul className="list">
              {savedDocs.map(doc => (
                <li key={doc.id} className="list-item">
                  <div style={{ display: 'flex', gap: 8, alignItems: 'center', flexWrap: 'wrap' }}>
                    <strong>[{formatOptions.find(f => f.id === doc.formatId)?.label}]</strong>
                    <span className="help">{new Date(doc.createdAt).toLocaleString()} â€” {doc.title}</span>
                  </div>
                  <div className="list-actions">
                    <button className="btn" onClick={() => loadDocument(doc.id)}>ë¶ˆëŸ¬ì™€ í¸ì§‘</button>
                    <button className="btn" onClick={() => copyDocument(doc.id)}>ë³µì‚¬</button>
                    <button className="btn btn-outline" onClick={() => deleteDocument(doc.id)}>ì‚­ì œ</button>
                  </div>
                </li>
              ))}
            </ul>
          )}
        </section>
      </main>
      <nav className="bottom-nav">
        <div className="nav-inner container">
          <button
            className={`tab-btn ${activeTab === 'record' ? 'active' : ''}`}
            onClick={() => scrollTo(recordRef, 'record')}
            aria-label="ë…¹ìŒ ì„¹ì…˜ìœ¼ë¡œ ì´ë™"
          >
            <Mic size={18} />
            <span className="tab-label">ë…¹ìŒ</span>
          </button>
          <button
            className={`tab-btn ${activeTab === 'compose' ? 'active' : ''}`}
            onClick={() => scrollTo(composeRef, 'compose')}
            aria-label="ë¬¸ì„œ ì„¹ì…˜ìœ¼ë¡œ ì´ë™"
          >
            <Brain size={18} />
            <span className="tab-label">ë¬¸ì„œ</span>
          </button>
          {/* STT íƒ­ ì œê±°ë¨ */}
          <button
            className={`tab-btn ${activeTab === 'saved' ? 'active' : ''}`}
            onClick={() => scrollTo(savedRef, 'saved')}
            aria-label="ì €ì¥ ë¬¸ì„œ ì„¹ì…˜ìœ¼ë¡œ ì´ë™"
          >
            <Folder size={18} />
            <span className="tab-label">ì €ì¥</span>
          </button>
        </div>
      </nav>
    </>
  )
}

export default App
